{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
      "cp: cannot stat 'kaggle.json': No such file or directory\n",
      "Downloading word2vec-nlp-tutorial.zip to /workspace/BagOfWordsMeetsBagsOfPopcorn\n",
      " 91%|██████████████████████████████████▌   | 47.0M/51.7M [00:00<00:00, 75.7MB/s]\n",
      "100%|██████████████████████████████████████| 51.7M/51.7M [00:00<00:00, 74.6MB/s]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "get kaggle dataset\n",
    "'''\n",
    "!pip install -q kaggle\n",
    "!mkdir ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "# !kaggle datasets list\n",
    "!kaggle competitions download -c word2vec-nlp-tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ./word2vec-nlp-tutorial.zip\n",
      "  inflating: labeledTrainData.tsv.zip  \n",
      "  inflating: sampleSubmission.csv    \n",
      "  inflating: testData.tsv.zip        \n",
      "  inflating: unlabeledTrainData.tsv.zip  \n"
     ]
    }
   ],
   "source": [
    "!unzip -o ./word2vec-nlp-tutorial.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ./labeledTrainData.tsv.zip\n",
      "  inflating: labeledTrainData.tsv    \n",
      "Archive:  ./testData.tsv.zip\n",
      "  inflating: testData.tsv            \n",
      "Archive:  ./unlabeledTrainData.tsv.zip\n",
      "  inflating: unlabeledTrainData.tsv  \n"
     ]
    }
   ],
   "source": [
    "!unzip -o ./labeledTrainData.tsv.zip\n",
    "!unzip -o ./testData.tsv.zip\n",
    "!unzip -o ./unlabeledTrainData.tsv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "import csv\n",
    "\n",
    "import bs4 as bs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize, sent_tokenize, pos_tag\n",
    "word_net_lemmatizer = WordNetLemmatizer()\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "import gensim\n",
    "from gensim.models import word2vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/omw-1.4.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "print(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Go', 'to', 'school', 'right', 'now']\n",
      "[('Go', 'VB'), ('to', 'TO'), ('school', 'NN'), ('right', 'RB'), ('now', 'RB')]\n"
     ]
    }
   ],
   "source": [
    "sentence = 'Go to school right now'\n",
    "tokens = nltk.word_tokenize(sentence)\n",
    "print(tokens)\n",
    "print(pos_tag(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_to_wordlist(review, remove_stopwords=False, lemmalization=False):\n",
    "    \n",
    "    # remove HTML tag\n",
    "    review_text = bs.BeautifulSoup(review).get_text()\n",
    "\n",
    "    # make non-English become space\n",
    "    review_text = re.sub(\"[^a-zA-Z]\", \" \", review_text)\n",
    "\n",
    "    words = review_text.lower().split()\n",
    "\n",
    "    \"\"\"\n",
    "    lemmalization 待做\n",
    "    \"\"\"\n",
    "    if lemmalization:\n",
    "        tagged_sentences = pos_tag(words)\n",
    "        lemma_senetence = []\n",
    "        for tag in tagged_sentences:\n",
    "            pos = get_wordnet_pos(tag[1]) or wordnet.NOUN\n",
    "            lemma_senetence.append(word_net_lemmatizer.lemmatize(tag[0], pos=pos))\n",
    "        \n",
    "        words = lemma_senetence\n",
    "    # for word in meaningful_words:\n",
    "    #     word = word_net_lemmatizer.lemmatize(word, 'v')\n",
    "\n",
    "    # remove stopword\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_to_sentences(review, remove_stopwords=False):\n",
    "    raw_sentences = tokenizer.tokenize(review.strip())\n",
    "\n",
    "    sentences = []\n",
    "\n",
    "    for raw_sentence in raw_sentences:\n",
    "\n",
    "        if len(raw_sentence) > 0:\n",
    "            sentences.append(review_to_wordlist(raw_sentence, remove_stopwords, lemmalization=True))\n",
    "\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id  sentiment                                             review\n",
      "0  5814_8          1  With all this stuff going down at the moment w...\n",
      "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
      "2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
      "        id                                             review\n",
      "0   9999_0  Watching Time Chasers, it obvious that it was ...\n",
      "1  45057_0  I saw this film about 20 years ago and remembe...\n",
      "2  15561_0  Minor Spoilers<br /><br />In New York, Joan Ba...\n",
      "['the', 'classic', 'war', 'of', 'the', 'worlds', 'by', 'timothy', 'hines', 'is', 'a', 'very', 'entertaining', 'film', 'that', 'obviously', 'goes', 'to', 'great', 'effort', 'and', 'lengths', 'to', 'faithfully', 'recreate', 'h', 'g', 'wells', 'classic', 'book', 'mr', 'hines', 'succeeds', 'in', 'doing', 'so', 'i', 'and', 'those', 'who', 'watched', 'his', 'film', 'with', 'me', 'appreciated', 'the', 'fact', 'that', 'it', 'was', 'not', 'the', 'standard', 'predictable', 'hollywood', 'fare', 'that', 'comes', 'out', 'every', 'year', 'e', 'g', 'the', 'spielberg', 'version', 'with', 'tom', 'cruise', 'that', 'had', 'only', 'the', 'slightest', 'resemblance', 'to', 'the', 'book', 'obviously', 'everyone', 'looks', 'for', 'different', 'things', 'in', 'a', 'movie', 'those', 'who', 'envision', 'themselves', 'as', 'amateur', 'critics', 'look', 'only', 'to', 'criticize', 'everything', 'they', 'can', 'others', 'rate', 'a', 'movie', 'on', 'more', 'important', 'bases', 'like', 'being', 'entertained', 'which', 'is', 'why', 'most', 'people', 'never', 'agree', 'with', 'the', 'critics', 'we', 'enjoyed', 'the', 'effort', 'mr', 'hines', 'put', 'into', 'being', 'faithful', 'to', 'h', 'g', 'wells', 'classic', 'novel', 'and', 'we', 'found', 'it', 'to', 'be', 'very', 'entertaining', 'this', 'made', 'it', 'easy', 'to', 'overlook', 'what', 'the', 'critics', 'perceive', 'to', 'be', 'its', 'shortcomings']\n"
     ]
    }
   ],
   "source": [
    "labeled_df = pd.read_csv('./labeledTrainData.tsv', sep='\\t', header=0)\n",
    "unlabeled_df = pd.read_csv('./unlabeledTrainData.tsv', sep='\\t', header=0, on_bad_lines='skip')\n",
    "test_df = pd.read_csv('./testData.tsv', sep='\\t', header=0)\n",
    "# print(labeled_df.iloc[1][2])\n",
    "words = review_to_wordlist(labeled_df.iloc[1][2])\n",
    "print(labeled_df.head(3))\n",
    "print(unlabeled_df.head(3))\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['with', 'all', 'this', 'stuff', 'go', 'down', 'at', 'the', 'moment', 'with', 'mj', 'i', 've', 'start', 'listen', 'to', 'his', 'music', 'watch', 'the', 'odd', 'documentary', 'here', 'and', 'there', 'watch', 'the', 'wiz', 'and', 'watch', 'moonwalker', 'again'], ['maybe', 'i', 'just', 'want', 'to', 'get', 'a', 'certain', 'insight', 'into', 'this', 'guy', 'who', 'i', 'think', 'be', 'really', 'cool', 'in', 'the', 'eighty', 'just', 'to', 'maybe', 'make', 'up', 'my', 'mind', 'whether', 'he', 'be', 'guilty', 'or', 'innocent'], ['moonwalker', 'be', 'part', 'biography', 'part', 'feature', 'film', 'which', 'i', 'remember', 'go', 'to', 'see', 'at', 'the', 'cinema', 'when', 'it', 'be', 'originally', 'release']]\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "\n",
    "for review in labeled_df['review']:\n",
    "    sentences += review_to_sentences(review)\n",
    "\n",
    "for review in unlabeled_df['review']:\n",
    "    sentences += review_to_sentences(review)\n",
    "\n",
    "for review in test_df['review']:\n",
    "    sentences += review_to_sentences(review)\n",
    "\n",
    "print(sentences[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2V_NUM_FEATURES = 512   # Word vector dimensionality\n",
    "W2V_MIN_WORD_COUNT = 60   # Minimum word count\n",
    "W2V_NUM_WORKERS = 4      # Number of threads to run in parallel\n",
    "W2V_CONTEXT = 10          # Context window size\n",
    "W2V_DOWNSAMPLING = 1e-3   # Downsample setting for frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-22 05:12:58,571 : INFO : collecting all words and their counts\n",
      "2022-03-22 05:12:58,572 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-22 05:12:58,623 : INFO : PROGRESS: at sentence #10000, processed 225803 words, keeping 14707 word types\n",
      "2022-03-22 05:12:58,656 : INFO : PROGRESS: at sentence #20000, processed 451842 words, keeping 20645 word types\n",
      "2022-03-22 05:12:58,719 : INFO : PROGRESS: at sentence #30000, processed 671053 words, keeping 24821 word types\n",
      "2022-03-22 05:12:58,759 : INFO : PROGRESS: at sentence #40000, processed 897624 words, keeping 28483 word types\n",
      "2022-03-22 05:12:58,791 : INFO : PROGRESS: at sentence #50000, processed 1120158 words, keeping 31460 word types\n",
      "2022-03-22 05:12:58,826 : INFO : PROGRESS: at sentence #60000, processed 1340913 words, keeping 34028 word types\n",
      "2022-03-22 05:12:58,858 : INFO : PROGRESS: at sentence #70000, processed 1564763 words, keeping 36271 word types\n",
      "2022-03-22 05:12:58,889 : INFO : PROGRESS: at sentence #80000, processed 1784082 words, keeping 38358 word types\n",
      "2022-03-22 05:12:58,921 : INFO : PROGRESS: at sentence #90000, processed 2007590 words, keeping 40480 word types\n",
      "2022-03-22 05:12:58,953 : INFO : PROGRESS: at sentence #100000, processed 2228932 words, keeping 42248 word types\n",
      "2022-03-22 05:12:58,985 : INFO : PROGRESS: at sentence #110000, processed 2449108 words, keeping 43906 word types\n",
      "2022-03-22 05:12:59,018 : INFO : PROGRESS: at sentence #120000, processed 2671053 words, keeping 45735 word types\n",
      "2022-03-22 05:12:59,051 : INFO : PROGRESS: at sentence #130000, processed 2896619 words, keeping 47251 word types\n",
      "2022-03-22 05:12:59,084 : INFO : PROGRESS: at sentence #140000, processed 3113151 words, keeping 48621 word types\n",
      "2022-03-22 05:12:59,128 : INFO : PROGRESS: at sentence #150000, processed 3338976 words, keeping 50116 word types\n",
      "2022-03-22 05:12:59,175 : INFO : PROGRESS: at sentence #160000, processed 3561883 words, keeping 51534 word types\n",
      "2022-03-22 05:12:59,207 : INFO : PROGRESS: at sentence #170000, processed 3785579 words, keeping 52855 word types\n",
      "2022-03-22 05:12:59,239 : INFO : PROGRESS: at sentence #180000, processed 4007541 words, keeping 54119 word types\n",
      "2022-03-22 05:12:59,271 : INFO : PROGRESS: at sentence #190000, processed 4232985 words, keeping 55325 word types\n",
      "2022-03-22 05:12:59,303 : INFO : PROGRESS: at sentence #200000, processed 4456605 words, keeping 56479 word types\n",
      "2022-03-22 05:12:59,335 : INFO : PROGRESS: at sentence #210000, processed 4678976 words, keeping 57706 word types\n",
      "2022-03-22 05:12:59,367 : INFO : PROGRESS: at sentence #220000, processed 4903687 words, keeping 58904 word types\n",
      "2022-03-22 05:12:59,399 : INFO : PROGRESS: at sentence #230000, processed 5125706 words, keeping 60059 word types\n",
      "2022-03-22 05:12:59,431 : INFO : PROGRESS: at sentence #240000, processed 5352561 words, keeping 61188 word types\n",
      "2022-03-22 05:12:59,462 : INFO : PROGRESS: at sentence #250000, processed 5566899 words, keeping 62259 word types\n",
      "2022-03-22 05:12:59,494 : INFO : PROGRESS: at sentence #260000, processed 5787064 words, keeping 63298 word types\n",
      "2022-03-22 05:12:59,528 : INFO : PROGRESS: at sentence #270000, processed 6010155 words, keeping 64500 word types\n",
      "2022-03-22 05:12:59,584 : INFO : PROGRESS: at sentence #280000, processed 6235746 words, keeping 66039 word types\n",
      "2022-03-22 05:12:59,618 : INFO : PROGRESS: at sentence #290000, processed 6458664 words, keeping 67381 word types\n",
      "2022-03-22 05:12:59,651 : INFO : PROGRESS: at sentence #300000, processed 6684774 words, keeping 68616 word types\n",
      "2022-03-22 05:12:59,683 : INFO : PROGRESS: at sentence #310000, processed 6909337 words, keeping 69843 word types\n",
      "2022-03-22 05:12:59,716 : INFO : PROGRESS: at sentence #320000, processed 7134686 words, keeping 71086 word types\n",
      "2022-03-22 05:12:59,779 : INFO : PROGRESS: at sentence #330000, processed 7357342 words, keeping 72239 word types\n",
      "2022-03-22 05:12:59,811 : INFO : PROGRESS: at sentence #340000, processed 7586125 words, keeping 73417 word types\n",
      "2022-03-22 05:12:59,844 : INFO : PROGRESS: at sentence #350000, processed 7809609 words, keeping 74531 word types\n",
      "2022-03-22 05:12:59,898 : INFO : PROGRESS: at sentence #360000, processed 8030005 words, keeping 75631 word types\n",
      "2022-03-22 05:12:59,930 : INFO : PROGRESS: at sentence #370000, processed 8259319 words, keeping 76668 word types\n",
      "2022-03-22 05:12:59,962 : INFO : PROGRESS: at sentence #380000, processed 8483236 words, keeping 77760 word types\n",
      "2022-03-22 05:12:59,995 : INFO : PROGRESS: at sentence #390000, processed 8713429 words, keeping 78703 word types\n",
      "2022-03-22 05:13:00,027 : INFO : PROGRESS: at sentence #400000, processed 8935252 words, keeping 79645 word types\n",
      "2022-03-22 05:13:00,058 : INFO : PROGRESS: at sentence #410000, processed 9156732 words, keeping 80566 word types\n",
      "2022-03-22 05:13:00,091 : INFO : PROGRESS: at sentence #420000, processed 9378762 words, keeping 81567 word types\n",
      "2022-03-22 05:13:00,125 : INFO : PROGRESS: at sentence #430000, processed 9606829 words, keeping 82523 word types\n",
      "2022-03-22 05:13:00,159 : INFO : PROGRESS: at sentence #440000, processed 9830976 words, keeping 83471 word types\n",
      "2022-03-22 05:13:00,193 : INFO : PROGRESS: at sentence #450000, processed 10056934 words, keeping 84536 word types\n",
      "2022-03-22 05:13:00,227 : INFO : PROGRESS: at sentence #460000, processed 10289333 words, keeping 85487 word types\n",
      "2022-03-22 05:13:00,261 : INFO : PROGRESS: at sentence #470000, processed 10517562 words, keeping 86288 word types\n",
      "2022-03-22 05:13:00,293 : INFO : PROGRESS: at sentence #480000, processed 10739130 words, keeping 87171 word types\n",
      "2022-03-22 05:13:00,327 : INFO : PROGRESS: at sentence #490000, processed 10964601 words, keeping 88116 word types\n",
      "2022-03-22 05:13:00,359 : INFO : PROGRESS: at sentence #500000, processed 11186992 words, keeping 88970 word types\n",
      "2022-03-22 05:13:00,392 : INFO : PROGRESS: at sentence #510000, processed 11411448 words, keeping 89829 word types\n",
      "2022-03-22 05:13:00,424 : INFO : PROGRESS: at sentence #520000, processed 11635238 words, keeping 90690 word types\n",
      "2022-03-22 05:13:00,456 : INFO : PROGRESS: at sentence #530000, processed 11859231 words, keeping 91469 word types\n",
      "2022-03-22 05:13:00,489 : INFO : PROGRESS: at sentence #540000, processed 12083740 words, keeping 92319 word types\n",
      "2022-03-22 05:13:00,522 : INFO : PROGRESS: at sentence #550000, processed 12309720 words, keeping 93166 word types\n",
      "2022-03-22 05:13:00,554 : INFO : PROGRESS: at sentence #560000, processed 12531576 words, keeping 93960 word types\n",
      "2022-03-22 05:13:00,588 : INFO : PROGRESS: at sentence #570000, processed 12759944 words, keeping 94725 word types\n",
      "2022-03-22 05:13:00,652 : INFO : PROGRESS: at sentence #580000, processed 12983234 words, keeping 95557 word types\n",
      "2022-03-22 05:13:00,686 : INFO : PROGRESS: at sentence #590000, processed 13207283 words, keeping 96360 word types\n",
      "2022-03-22 05:13:00,719 : INFO : PROGRESS: at sentence #600000, processed 13428144 words, keeping 97043 word types\n",
      "2022-03-22 05:13:00,751 : INFO : PROGRESS: at sentence #610000, processed 13651090 words, keeping 97884 word types\n",
      "2022-03-22 05:13:00,818 : INFO : PROGRESS: at sentence #620000, processed 13876084 words, keeping 98599 word types\n",
      "2022-03-22 05:13:00,852 : INFO : PROGRESS: at sentence #630000, processed 14100608 words, keeping 99305 word types\n",
      "2022-03-22 05:13:00,884 : INFO : PROGRESS: at sentence #640000, processed 14321812 words, keeping 100084 word types\n",
      "2022-03-22 05:13:00,917 : INFO : PROGRESS: at sentence #650000, processed 14547881 words, keeping 100847 word types\n",
      "2022-03-22 05:13:00,949 : INFO : PROGRESS: at sentence #660000, processed 14771076 words, keeping 101571 word types\n",
      "2022-03-22 05:13:00,981 : INFO : PROGRESS: at sentence #670000, processed 14994511 words, keeping 102242 word types\n",
      "2022-03-22 05:13:01,014 : INFO : PROGRESS: at sentence #680000, processed 15218250 words, keeping 102920 word types\n",
      "2022-03-22 05:13:01,046 : INFO : PROGRESS: at sentence #690000, processed 15440840 words, keeping 103672 word types\n",
      "2022-03-22 05:13:01,080 : INFO : PROGRESS: at sentence #700000, processed 15670093 words, keeping 104447 word types\n",
      "2022-03-22 05:13:01,143 : INFO : PROGRESS: at sentence #710000, processed 15893070 words, keeping 105082 word types\n",
      "2022-03-22 05:13:01,178 : INFO : PROGRESS: at sentence #720000, processed 16118867 words, keeping 105691 word types\n",
      "2022-03-22 05:13:01,211 : INFO : PROGRESS: at sentence #730000, processed 16345147 words, keeping 106408 word types\n",
      "2022-03-22 05:13:01,244 : INFO : PROGRESS: at sentence #740000, processed 16565018 words, keeping 107069 word types\n",
      "2022-03-22 05:13:01,278 : INFO : PROGRESS: at sentence #750000, processed 16785953 words, keeping 107698 word types\n",
      "2022-03-22 05:13:01,311 : INFO : PROGRESS: at sentence #760000, processed 17003117 words, keeping 108311 word types\n",
      "2022-03-22 05:13:01,345 : INFO : PROGRESS: at sentence #770000, processed 17231217 words, keeping 109036 word types\n",
      "2022-03-22 05:13:01,379 : INFO : PROGRESS: at sentence #780000, processed 17460517 words, keeping 109704 word types\n",
      "2022-03-22 05:13:01,413 : INFO : PROGRESS: at sentence #790000, processed 17688581 words, keeping 110369 word types\n",
      "2022-03-22 05:13:01,446 : INFO : PROGRESS: at sentence #800000, processed 17911049 words, keeping 111202 word types\n",
      "2022-03-22 05:13:01,480 : INFO : PROGRESS: at sentence #810000, processed 18137844 words, keeping 112139 word types\n",
      "2022-03-22 05:13:01,512 : INFO : PROGRESS: at sentence #820000, processed 18358176 words, keeping 113018 word types\n",
      "2022-03-22 05:13:01,545 : INFO : PROGRESS: at sentence #830000, processed 18578628 words, keeping 113836 word types\n",
      "2022-03-22 05:13:01,577 : INFO : PROGRESS: at sentence #840000, processed 18798897 words, keeping 114544 word types\n",
      "2022-03-22 05:13:01,611 : INFO : PROGRESS: at sentence #850000, processed 19021905 words, keeping 115239 word types\n",
      "2022-03-22 05:13:01,646 : INFO : PROGRESS: at sentence #860000, processed 19245806 words, keeping 116028 word types\n",
      "2022-03-22 05:13:01,680 : INFO : PROGRESS: at sentence #870000, processed 19466669 words, keeping 116709 word types\n",
      "2022-03-22 05:13:01,712 : INFO : PROGRESS: at sentence #880000, processed 19683885 words, keeping 117337 word types\n",
      "2022-03-22 05:13:01,745 : INFO : PROGRESS: at sentence #890000, processed 19906423 words, keeping 118088 word types\n",
      "2022-03-22 05:13:01,776 : INFO : PROGRESS: at sentence #900000, processed 20120038 words, keeping 118670 word types\n",
      "2022-03-22 05:13:01,810 : INFO : PROGRESS: at sentence #910000, processed 20344041 words, keeping 119244 word types\n",
      "2022-03-22 05:13:01,844 : INFO : PROGRESS: at sentence #920000, processed 20570087 words, keeping 119862 word types\n",
      "2022-03-22 05:13:01,910 : INFO : PROGRESS: at sentence #930000, processed 20789952 words, keeping 120562 word types\n",
      "2022-03-22 05:13:01,978 : INFO : PROGRESS: at sentence #940000, processed 21011046 words, keeping 121182 word types\n",
      "2022-03-22 05:13:02,013 : INFO : PROGRESS: at sentence #950000, processed 21235224 words, keeping 121864 word types\n",
      "2022-03-22 05:13:02,045 : INFO : PROGRESS: at sentence #960000, processed 21456846 words, keeping 122470 word types\n",
      "2022-03-22 05:13:02,078 : INFO : PROGRESS: at sentence #970000, processed 21679063 words, keeping 123088 word types\n",
      "2022-03-22 05:13:02,110 : INFO : PROGRESS: at sentence #980000, processed 21895451 words, keeping 123667 word types\n",
      "2022-03-22 05:13:02,142 : INFO : PROGRESS: at sentence #990000, processed 22117739 words, keeping 124279 word types\n",
      "2022-03-22 05:13:02,176 : INFO : PROGRESS: at sentence #1000000, processed 22337510 words, keeping 124880 word types\n",
      "2022-03-22 05:13:02,236 : INFO : PROGRESS: at sentence #1010000, processed 22555505 words, keeping 125474 word types\n",
      "2022-03-22 05:13:02,270 : INFO : PROGRESS: at sentence #1020000, processed 22778152 words, keeping 126090 word types\n",
      "2022-03-22 05:13:02,303 : INFO : PROGRESS: at sentence #1030000, processed 22999590 words, keeping 126666 word types\n",
      "2022-03-22 05:13:02,337 : INFO : PROGRESS: at sentence #1040000, processed 23220417 words, keeping 127235 word types\n",
      "2022-03-22 05:13:02,371 : INFO : PROGRESS: at sentence #1050000, processed 23441218 words, keeping 127764 word types\n",
      "2022-03-22 05:13:02,393 : INFO : collected 128121 word types from a corpus of 23583894 raw words and 1056248 sentences\n",
      "2022-03-22 05:13:02,394 : INFO : Creating a fresh vocabulary\n",
      "2022-03-22 05:13:02,473 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=60 retains 12625 unique words (9.853966172602462%% of original 128121, drops 115496)', 'datetime': '2022-03-22T05:13:02.473162', 'gensim': '4.1.2', 'python': '3.7.11 (default, Jul 27 2021, 14:32:16) \\n[GCC 7.5.0]', 'platform': 'Linux-5.4.0-100-generic-x86_64-with-debian-buster-sid', 'event': 'prepare_vocab'}\n",
      "2022-03-22 05:13:02,473 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=60 leaves 22903271 word corpus (97.11403468824953%% of original 23583894, drops 680623)', 'datetime': '2022-03-22T05:13:02.473985', 'gensim': '4.1.2', 'python': '3.7.11 (default, Jul 27 2021, 14:32:16) \\n[GCC 7.5.0]', 'platform': 'Linux-5.4.0-100-generic-x86_64-with-debian-buster-sid', 'event': 'prepare_vocab'}\n",
      "2022-03-22 05:13:02,530 : INFO : deleting the raw counts dictionary of 128121 items\n",
      "2022-03-22 05:13:02,534 : INFO : sample=0.001 downsamples 49 most-common words\n",
      "2022-03-22 05:13:02,534 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 16326348.31655428 word corpus (71.3%% of prior 22903271)', 'datetime': '2022-03-22T05:13:02.534970', 'gensim': '4.1.2', 'python': '3.7.11 (default, Jul 27 2021, 14:32:16) \\n[GCC 7.5.0]', 'platform': 'Linux-5.4.0-100-generic-x86_64-with-debian-buster-sid', 'event': 'prepare_vocab'}\n",
      "2022-03-22 05:13:02,635 : INFO : estimated required memory for 12625 words and 512 dimensions: 58024500 bytes\n",
      "2022-03-22 05:13:02,636 : INFO : resetting layer weights\n",
      "2022-03-22 05:13:02,659 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-22T05:13:02.659586', 'gensim': '4.1.2', 'python': '3.7.11 (default, Jul 27 2021, 14:32:16) \\n[GCC 7.5.0]', 'platform': 'Linux-5.4.0-100-generic-x86_64-with-debian-buster-sid', 'event': 'build_vocab'}\n",
      "2022-03-22 05:13:02,660 : INFO : Word2Vec lifecycle event {'msg': 'training model with 4 workers on 12625 vocabulary and 512 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2022-03-22T05:13:02.660622', 'gensim': '4.1.2', 'python': '3.7.11 (default, Jul 27 2021, 14:32:16) \\n[GCC 7.5.0]', 'platform': 'Linux-5.4.0-100-generic-x86_64-with-debian-buster-sid', 'event': 'train'}\n",
      "2022-03-22 05:13:03,751 : INFO : EPOCH 1 - PROGRESS: at 1.22% examples, 186995 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:13:04,765 : INFO : EPOCH 1 - PROGRESS: at 2.58% examples, 202308 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:13:05,780 : INFO : EPOCH 1 - PROGRESS: at 3.91% examples, 207169 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:13:06,806 : INFO : EPOCH 1 - PROGRESS: at 5.27% examples, 209226 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:13:07,821 : INFO : EPOCH 1 - PROGRESS: at 6.60% examples, 209601 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:13:08,839 : INFO : EPOCH 1 - PROGRESS: at 7.96% examples, 210807 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:13:09,901 : INFO : EPOCH 1 - PROGRESS: at 9.32% examples, 210492 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:13:10,922 : INFO : EPOCH 1 - PROGRESS: at 10.71% examples, 211277 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:13:11,923 : INFO : EPOCH 1 - PROGRESS: at 12.00% examples, 211597 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:13:12,973 : INFO : EPOCH 1 - PROGRESS: at 13.38% examples, 211443 words/s, in_qsize 6, out_qsize 1\n",
      "2022-03-22 05:13:14,013 : INFO : EPOCH 1 - PROGRESS: at 14.74% examples, 211530 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:13:15,046 : INFO : EPOCH 1 - PROGRESS: at 16.09% examples, 211774 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:13:16,058 : INFO : EPOCH 1 - PROGRESS: at 17.45% examples, 212280 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:13:17,077 : INFO : EPOCH 1 - PROGRESS: at 18.79% examples, 212622 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:13:18,097 : INFO : EPOCH 1 - PROGRESS: at 20.15% examples, 212889 words/s, in_qsize 8, out_qsize 0\n",
      "2022-03-22 05:13:19,100 : INFO : EPOCH 1 - PROGRESS: at 21.46% examples, 212908 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:13:20,111 : INFO : EPOCH 1 - PROGRESS: at 22.72% examples, 212438 words/s, in_qsize 8, out_qsize 0\n",
      "2022-03-22 05:13:21,138 : INFO : EPOCH 1 - PROGRESS: at 24.12% examples, 212580 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:13:22,167 : INFO : EPOCH 1 - PROGRESS: at 25.48% examples, 212679 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:13:23,201 : INFO : EPOCH 1 - PROGRESS: at 26.83% examples, 212741 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:13:24,236 : INFO : EPOCH 1 - PROGRESS: at 28.16% examples, 212792 words/s, in_qsize 8, out_qsize 0\n",
      "2022-03-22 05:13:25,266 : INFO : EPOCH 1 - PROGRESS: at 29.52% examples, 212875 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:13:26,314 : INFO : EPOCH 1 - PROGRESS: at 30.86% examples, 212788 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:13:27,339 : INFO : EPOCH 1 - PROGRESS: at 32.19% examples, 212929 words/s, in_qsize 8, out_qsize 0\n",
      "2022-03-22 05:13:28,377 : INFO : EPOCH 1 - PROGRESS: at 33.55% examples, 212961 words/s, in_qsize 8, out_qsize 0\n",
      "2022-03-22 05:13:29,390 : INFO : EPOCH 1 - PROGRESS: at 34.89% examples, 213147 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:13:30,404 : INFO : EPOCH 1 - PROGRESS: at 36.19% examples, 213075 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:13:31,448 : INFO : EPOCH 1 - PROGRESS: at 37.52% examples, 213034 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:13:32,485 : INFO : EPOCH 1 - PROGRESS: at 38.89% examples, 213041 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:13:33,531 : INFO : EPOCH 1 - PROGRESS: at 40.24% examples, 212990 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:13:34,585 : INFO : EPOCH 1 - PROGRESS: at 41.57% examples, 212885 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:13:35,627 : INFO : EPOCH 1 - PROGRESS: at 42.91% examples, 212863 words/s, in_qsize 8, out_qsize 0\n",
      "2022-03-22 05:13:36,666 : INFO : EPOCH 1 - PROGRESS: at 44.23% examples, 212864 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:13:37,677 : INFO : EPOCH 1 - PROGRESS: at 45.58% examples, 213040 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:13:38,686 : INFO : EPOCH 1 - PROGRESS: at 46.83% examples, 212830 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:13:39,703 : INFO : EPOCH 1 - PROGRESS: at 48.15% examples, 212780 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:13:40,729 : INFO : EPOCH 1 - PROGRESS: at 49.50% examples, 212863 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:13:41,738 : INFO : EPOCH 1 - PROGRESS: at 50.80% examples, 212851 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:13:42,742 : INFO : EPOCH 1 - PROGRESS: at 52.11% examples, 212867 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:13:43,760 : INFO : EPOCH 1 - PROGRESS: at 53.46% examples, 212974 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:13:44,792 : INFO : EPOCH 1 - PROGRESS: at 54.81% examples, 213014 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:13:45,817 : INFO : EPOCH 1 - PROGRESS: at 56.16% examples, 213078 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:13:46,860 : INFO : EPOCH 1 - PROGRESS: at 57.52% examples, 213051 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:13:47,899 : INFO : EPOCH 1 - PROGRESS: at 58.85% examples, 213052 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:13:48,941 : INFO : EPOCH 1 - PROGRESS: at 60.22% examples, 213030 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:13:49,963 : INFO : EPOCH 1 - PROGRESS: at 61.56% examples, 213108 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:13:50,973 : INFO : EPOCH 1 - PROGRESS: at 62.93% examples, 213229 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:13:52,018 : INFO : EPOCH 1 - PROGRESS: at 64.27% examples, 213208 words/s, in_qsize 8, out_qsize 0\n",
      "2022-03-22 05:13:53,046 : INFO : EPOCH 1 - PROGRESS: at 65.62% examples, 213248 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:13:54,083 : INFO : EPOCH 1 - PROGRESS: at 66.96% examples, 213249 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:13:55,104 : INFO : EPOCH 1 - PROGRESS: at 68.26% examples, 213183 words/s, in_qsize 8, out_qsize 0\n",
      "2022-03-22 05:13:56,141 : INFO : EPOCH 1 - PROGRESS: at 69.61% examples, 213188 words/s, in_qsize 8, out_qsize 0\n",
      "2022-03-22 05:13:57,182 : INFO : EPOCH 1 - PROGRESS: at 70.98% examples, 213168 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:13:58,183 : INFO : EPOCH 1 - PROGRESS: at 72.35% examples, 213306 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:13:59,185 : INFO : EPOCH 1 - PROGRESS: at 73.59% examples, 213193 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:14:00,217 : INFO : EPOCH 1 - PROGRESS: at 74.87% examples, 213093 words/s, in_qsize 7, out_qsize 1\n",
      "2022-03-22 05:14:01,234 : INFO : EPOCH 1 - PROGRESS: at 76.22% examples, 213155 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:14:02,245 : INFO : EPOCH 1 - PROGRESS: at 77.59% examples, 213240 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:14:03,253 : INFO : EPOCH 1 - PROGRESS: at 78.92% examples, 213222 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:14:04,288 : INFO : EPOCH 1 - PROGRESS: at 80.28% examples, 213230 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:14:05,307 : INFO : EPOCH 1 - PROGRESS: at 81.63% examples, 213283 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:14:06,323 : INFO : EPOCH 1 - PROGRESS: at 83.01% examples, 213359 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:14:07,334 : INFO : EPOCH 1 - PROGRESS: at 84.39% examples, 213443 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:14:08,344 : INFO : EPOCH 1 - PROGRESS: at 85.77% examples, 213527 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:14:09,348 : INFO : EPOCH 1 - PROGRESS: at 86.99% examples, 213321 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:14:10,371 : INFO : EPOCH 1 - PROGRESS: at 88.36% examples, 213366 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:14:11,410 : INFO : EPOCH 1 - PROGRESS: at 89.71% examples, 213363 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:14:12,419 : INFO : EPOCH 1 - PROGRESS: at 91.08% examples, 213436 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:14:13,431 : INFO : EPOCH 1 - PROGRESS: at 92.46% examples, 213510 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:14:14,431 : INFO : EPOCH 1 - PROGRESS: at 93.78% examples, 213510 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:14:15,461 : INFO : EPOCH 1 - PROGRESS: at 95.19% examples, 213527 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:14:16,499 : INFO : EPOCH 1 - PROGRESS: at 96.53% examples, 213519 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:14:17,534 : INFO : EPOCH 1 - PROGRESS: at 97.90% examples, 213523 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:14:18,552 : INFO : EPOCH 1 - PROGRESS: at 99.27% examples, 213571 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:14:18,993 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-03-22 05:14:19,067 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-22 05:14:19,076 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-22 05:14:19,088 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-22 05:14:19,089 : INFO : EPOCH - 1 : training on 23583894 raw words (16325630 effective words) took 76.4s, 213659 effective words/s\n",
      "2022-03-22 05:14:20,151 : INFO : EPOCH 2 - PROGRESS: at 1.22% examples, 190084 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:14:21,172 : INFO : EPOCH 2 - PROGRESS: at 2.58% examples, 203438 words/s, in_qsize 7, out_qsize 1\n",
      "2022-03-22 05:14:22,181 : INFO : EPOCH 2 - PROGRESS: at 3.87% examples, 206143 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:14:23,205 : INFO : EPOCH 2 - PROGRESS: at 5.23% examples, 208469 words/s, in_qsize 6, out_qsize 1\n",
      "2022-03-22 05:14:24,233 : INFO : EPOCH 2 - PROGRESS: at 6.60% examples, 209787 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:14:25,246 : INFO : EPOCH 2 - PROGRESS: at 7.96% examples, 211179 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:14:26,252 : INFO : EPOCH 2 - PROGRESS: at 9.29% examples, 211486 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:14:27,269 : INFO : EPOCH 2 - PROGRESS: at 10.61% examples, 211467 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:14:28,299 : INFO : EPOCH 2 - PROGRESS: at 11.92% examples, 211106 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:14:29,323 : INFO : EPOCH 2 - PROGRESS: at 13.30% examples, 211558 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:14:30,331 : INFO : EPOCH 2 - PROGRESS: at 14.61% examples, 211605 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:14:31,345 : INFO : EPOCH 2 - PROGRESS: at 15.92% examples, 211617 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:14:32,355 : INFO : EPOCH 2 - PROGRESS: at 17.28% examples, 212201 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:14:33,357 : INFO : EPOCH 2 - PROGRESS: at 18.59% examples, 212349 words/s, in_qsize 8, out_qsize 0\n",
      "2022-03-22 05:14:34,394 : INFO : EPOCH 2 - PROGRESS: at 19.90% examples, 211946 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:14:35,424 : INFO : EPOCH 2 - PROGRESS: at 21.25% examples, 212100 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:14:36,445 : INFO : EPOCH 2 - PROGRESS: at 22.55% examples, 211966 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:14:37,457 : INFO : EPOCH 2 - PROGRESS: at 23.91% examples, 211947 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:14:38,492 : INFO : EPOCH 2 - PROGRESS: at 25.27% examples, 212015 words/s, in_qsize 8, out_qsize 0\n",
      "2022-03-22 05:14:39,509 : INFO : EPOCH 2 - PROGRESS: at 26.61% examples, 212296 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:14:40,535 : INFO : EPOCH 2 - PROGRESS: at 27.95% examples, 212449 words/s, in_qsize 8, out_qsize 0\n",
      "2022-03-22 05:14:41,553 : INFO : EPOCH 2 - PROGRESS: at 29.26% examples, 212370 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:14:42,573 : INFO : EPOCH 2 - PROGRESS: at 30.56% examples, 212265 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:14:43,576 : INFO : EPOCH 2 - PROGRESS: at 31.85% examples, 212334 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:14:44,596 : INFO : EPOCH 2 - PROGRESS: at 33.16% examples, 212258 words/s, in_qsize 8, out_qsize 0\n",
      "2022-03-22 05:14:45,616 : INFO : EPOCH 2 - PROGRESS: at 34.52% examples, 212426 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:14:46,672 : INFO : EPOCH 2 - PROGRESS: at 35.85% examples, 212326 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:14:47,679 : INFO : EPOCH 2 - PROGRESS: at 37.14% examples, 212354 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:14:48,722 : INFO : EPOCH 2 - PROGRESS: at 38.51% examples, 212333 words/s, in_qsize 8, out_qsize 0\n",
      "2022-03-22 05:14:49,766 : INFO : EPOCH 2 - PROGRESS: at 39.87% examples, 212315 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:14:50,830 : INFO : EPOCH 2 - PROGRESS: at 41.19% examples, 212155 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:14:51,850 : INFO : EPOCH 2 - PROGRESS: at 42.54% examples, 212292 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:14:52,881 : INFO : EPOCH 2 - PROGRESS: at 43.85% examples, 212355 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:14:53,882 : INFO : EPOCH 2 - PROGRESS: at 45.15% examples, 212405 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:14:54,929 : INFO : EPOCH 2 - PROGRESS: at 46.50% examples, 212374 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:14:55,933 : INFO : EPOCH 2 - PROGRESS: at 47.82% examples, 212401 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:14:56,940 : INFO : EPOCH 2 - PROGRESS: at 49.12% examples, 212418 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:14:57,970 : INFO : EPOCH 2 - PROGRESS: at 50.46% examples, 212481 words/s, in_qsize 8, out_qsize 0\n",
      "2022-03-22 05:14:58,996 : INFO : EPOCH 2 - PROGRESS: at 51.79% examples, 212383 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:15:00,027 : INFO : EPOCH 2 - PROGRESS: at 53.12% examples, 212436 words/s, in_qsize 8, out_qsize 0\n",
      "2022-03-22 05:15:01,060 : INFO : EPOCH 2 - PROGRESS: at 54.46% examples, 212481 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:15:02,102 : INFO : EPOCH 2 - PROGRESS: at 55.81% examples, 212469 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:15:03,126 : INFO : EPOCH 2 - PROGRESS: at 57.18% examples, 212553 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:15:04,192 : INFO : EPOCH 2 - PROGRESS: at 58.53% examples, 212433 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:15:05,217 : INFO : EPOCH 2 - PROGRESS: at 59.88% examples, 212510 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:15:06,272 : INFO : EPOCH 2 - PROGRESS: at 61.23% examples, 212441 words/s, in_qsize 8, out_qsize 0\n",
      "2022-03-22 05:15:07,310 : INFO : EPOCH 2 - PROGRESS: at 62.59% examples, 212457 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:15:08,359 : INFO : EPOCH 2 - PROGRESS: at 63.92% examples, 212421 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:15:09,384 : INFO : EPOCH 2 - PROGRESS: at 65.29% examples, 212498 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:15:10,392 : INFO : EPOCH 2 - PROGRESS: at 66.57% examples, 212506 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:15:11,413 : INFO : EPOCH 2 - PROGRESS: at 67.87% examples, 212454 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:15:12,481 : INFO : EPOCH 2 - PROGRESS: at 69.22% examples, 212346 words/s, in_qsize 8, out_qsize 0\n",
      "2022-03-22 05:15:13,496 : INFO : EPOCH 2 - PROGRESS: at 70.59% examples, 212449 words/s, in_qsize 8, out_qsize 0\n",
      "2022-03-22 05:15:14,529 : INFO : EPOCH 2 - PROGRESS: at 71.98% examples, 212478 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:15:15,559 : INFO : EPOCH 2 - PROGRESS: at 73.26% examples, 212396 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:15:16,612 : INFO : EPOCH 2 - PROGRESS: at 74.59% examples, 212357 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:15:17,640 : INFO : EPOCH 2 - PROGRESS: at 75.93% examples, 212396 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:15:18,703 : INFO : EPOCH 2 - PROGRESS: at 77.29% examples, 212304 words/s, in_qsize 8, out_qsize 0\n",
      "2022-03-22 05:15:19,747 : INFO : EPOCH 2 - PROGRESS: at 78.66% examples, 212284 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:15:20,768 : INFO : EPOCH 2 - PROGRESS: at 80.03% examples, 212355 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:15:21,772 : INFO : EPOCH 2 - PROGRESS: at 81.37% examples, 212482 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:15:22,804 : INFO : EPOCH 2 - PROGRESS: at 82.75% examples, 212517 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:15:23,815 : INFO : EPOCH 2 - PROGRESS: at 84.12% examples, 212614 words/s, in_qsize 8, out_qsize 0\n",
      "2022-03-22 05:15:24,823 : INFO : EPOCH 2 - PROGRESS: at 85.47% examples, 212612 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:15:25,848 : INFO : EPOCH 2 - PROGRESS: at 86.79% examples, 212558 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:15:26,881 : INFO : EPOCH 2 - PROGRESS: at 88.15% examples, 212586 words/s, in_qsize 8, out_qsize 0\n",
      "2022-03-22 05:15:27,898 : INFO : EPOCH 2 - PROGRESS: at 89.52% examples, 212660 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:15:28,933 : INFO : EPOCH 2 - PROGRESS: at 90.87% examples, 212672 words/s, in_qsize 8, out_qsize 0\n",
      "2022-03-22 05:15:29,961 : INFO : EPOCH 2 - PROGRESS: at 92.28% examples, 212801 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:15:30,965 : INFO : EPOCH 2 - PROGRESS: at 93.61% examples, 212798 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:15:31,987 : INFO : EPOCH 2 - PROGRESS: at 95.00% examples, 212844 words/s, in_qsize 8, out_qsize 0\n",
      "2022-03-22 05:15:32,989 : INFO : EPOCH 2 - PROGRESS: at 96.28% examples, 212767 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:15:34,019 : INFO : EPOCH 2 - PROGRESS: at 97.64% examples, 212799 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:15:35,047 : INFO : EPOCH 2 - PROGRESS: at 99.01% examples, 212829 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:15:35,700 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-03-22 05:15:35,754 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-22 05:15:35,755 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-22 05:15:35,763 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-22 05:15:35,764 : INFO : EPOCH - 2 : training on 23583894 raw words (16327007 effective words) took 76.7s, 212961 effective words/s\n",
      "2022-03-22 05:15:36,821 : INFO : EPOCH 3 - PROGRESS: at 1.22% examples, 190728 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:15:37,837 : INFO : EPOCH 3 - PROGRESS: at 2.58% examples, 204097 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:15:38,842 : INFO : EPOCH 3 - PROGRESS: at 3.91% examples, 209218 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:15:39,847 : INFO : EPOCH 3 - PROGRESS: at 5.19% examples, 208408 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:15:40,852 : INFO : EPOCH 3 - PROGRESS: at 6.56% examples, 210693 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:15:41,890 : INFO : EPOCH 3 - PROGRESS: at 7.92% examples, 211067 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:15:42,934 : INFO : EPOCH 3 - PROGRESS: at 9.29% examples, 211231 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:15:43,946 : INFO : EPOCH 3 - PROGRESS: at 10.66% examples, 212190 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:15:44,993 : INFO : EPOCH 3 - PROGRESS: at 12.00% examples, 212120 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:15:46,037 : INFO : EPOCH 3 - PROGRESS: at 13.38% examples, 212060 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:15:47,077 : INFO : EPOCH 3 - PROGRESS: at 14.74% examples, 212079 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:15:48,140 : INFO : EPOCH 3 - PROGRESS: at 16.09% examples, 211767 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:15:49,156 : INFO : EPOCH 3 - PROGRESS: at 17.45% examples, 212205 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:15:50,187 : INFO : EPOCH 3 - PROGRESS: at 18.79% examples, 212380 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:15:51,206 : INFO : EPOCH 3 - PROGRESS: at 20.15% examples, 212662 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:15:52,225 : INFO : EPOCH 3 - PROGRESS: at 21.46% examples, 212477 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:15:53,233 : INFO : EPOCH 3 - PROGRESS: at 22.80% examples, 212872 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:15:54,251 : INFO : EPOCH 3 - PROGRESS: at 24.20% examples, 213103 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:15:55,263 : INFO : EPOCH 3 - PROGRESS: at 25.52% examples, 213023 words/s, in_qsize 8, out_qsize 0\n",
      "2022-03-22 05:15:56,282 : INFO : EPOCH 3 - PROGRESS: at 26.83% examples, 212886 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:15:57,289 : INFO : EPOCH 3 - PROGRESS: at 28.13% examples, 212887 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:15:58,330 : INFO : EPOCH 3 - PROGRESS: at 29.48% examples, 212861 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:15:59,358 : INFO : EPOCH 3 - PROGRESS: at 30.82% examples, 212942 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:16:00,361 : INFO : EPOCH 3 - PROGRESS: at 32.10% examples, 212979 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:16:01,365 : INFO : EPOCH 3 - PROGRESS: at 33.42% examples, 213016 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:16:02,384 : INFO : EPOCH 3 - PROGRESS: at 34.72% examples, 212909 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:16:03,404 : INFO : EPOCH 3 - PROGRESS: at 36.02% examples, 212816 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:16:04,433 : INFO : EPOCH 3 - PROGRESS: at 37.31% examples, 212655 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:16:05,467 : INFO : EPOCH 3 - PROGRESS: at 38.68% examples, 212695 words/s, in_qsize 8, out_qsize 0\n",
      "2022-03-22 05:16:06,493 : INFO : EPOCH 3 - PROGRESS: at 40.03% examples, 212793 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:16:07,524 : INFO : EPOCH 3 - PROGRESS: at 41.37% examples, 212825 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:16:08,533 : INFO : EPOCH 3 - PROGRESS: at 42.71% examples, 213031 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:16:09,546 : INFO : EPOCH 3 - PROGRESS: at 43.98% examples, 212979 words/s, in_qsize 8, out_qsize 0\n",
      "2022-03-22 05:16:10,583 : INFO : EPOCH 3 - PROGRESS: at 45.33% examples, 212998 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:16:11,584 : INFO : EPOCH 3 - PROGRESS: at 46.62% examples, 213025 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:16:12,608 : INFO : EPOCH 3 - PROGRESS: at 47.99% examples, 213102 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:16:13,614 : INFO : EPOCH 3 - PROGRESS: at 49.29% examples, 213105 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:16:14,630 : INFO : EPOCH 3 - PROGRESS: at 50.63% examples, 213217 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:16:15,673 : INFO : EPOCH 3 - PROGRESS: at 51.98% examples, 213187 words/s, in_qsize 8, out_qsize 0\n",
      "2022-03-22 05:16:16,707 : INFO : EPOCH 3 - PROGRESS: at 53.33% examples, 213207 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:16:17,751 : INFO : EPOCH 3 - PROGRESS: at 54.68% examples, 213176 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:16:18,764 : INFO : EPOCH 3 - PROGRESS: at 56.03% examples, 213302 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:16:19,789 : INFO : EPOCH 3 - PROGRESS: at 57.40% examples, 213363 words/s, in_qsize 8, out_qsize 0\n",
      "2022-03-22 05:16:20,834 : INFO : EPOCH 3 - PROGRESS: at 58.74% examples, 213321 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:16:21,874 : INFO : EPOCH 3 - PROGRESS: at 60.10% examples, 213297 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:16:22,887 : INFO : EPOCH 3 - PROGRESS: at 61.44% examples, 213407 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:16:23,906 : INFO : EPOCH 3 - PROGRESS: at 62.76% examples, 213349 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:16:24,923 : INFO : EPOCH 3 - PROGRESS: at 64.10% examples, 213437 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:16:25,926 : INFO : EPOCH 3 - PROGRESS: at 65.37% examples, 213313 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:16:26,943 : INFO : EPOCH 3 - PROGRESS: at 66.70% examples, 213389 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:16:27,968 : INFO : EPOCH 3 - PROGRESS: at 68.01% examples, 213314 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:16:28,989 : INFO : EPOCH 3 - PROGRESS: at 69.35% examples, 213377 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:16:30,034 : INFO : EPOCH 3 - PROGRESS: at 70.72% examples, 213342 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:16:31,053 : INFO : EPOCH 3 - PROGRESS: at 72.10% examples, 213410 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:16:32,078 : INFO : EPOCH 3 - PROGRESS: at 73.43% examples, 213449 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:16:33,082 : INFO : EPOCH 3 - PROGRESS: at 74.75% examples, 213577 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:16:34,111 : INFO : EPOCH 3 - PROGRESS: at 75.97% examples, 213231 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:16:35,136 : INFO : EPOCH 3 - PROGRESS: at 77.33% examples, 213264 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:16:36,167 : INFO : EPOCH 3 - PROGRESS: at 78.70% examples, 213268 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:16:37,222 : INFO : EPOCH 3 - PROGRESS: at 80.07% examples, 213210 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:16:38,273 : INFO : EPOCH 3 - PROGRESS: at 81.42% examples, 213159 words/s, in_qsize 8, out_qsize 0\n",
      "2022-03-22 05:16:39,279 : INFO : EPOCH 3 - PROGRESS: at 82.79% examples, 213265 words/s, in_qsize 8, out_qsize 0\n",
      "2022-03-22 05:16:40,292 : INFO : EPOCH 3 - PROGRESS: at 84.17% examples, 213342 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:16:41,317 : INFO : EPOCH 3 - PROGRESS: at 85.57% examples, 213382 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:16:42,356 : INFO : EPOCH 3 - PROGRESS: at 86.91% examples, 213377 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:16:43,375 : INFO : EPOCH 3 - PROGRESS: at 88.28% examples, 213439 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:16:44,379 : INFO : EPOCH 3 - PROGRESS: at 89.60% examples, 213439 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:16:45,384 : INFO : EPOCH 3 - PROGRESS: at 90.91% examples, 213432 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:16:46,413 : INFO : EPOCH 3 - PROGRESS: at 92.24% examples, 213354 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:16:47,442 : INFO : EPOCH 3 - PROGRESS: at 93.61% examples, 213367 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:16:48,457 : INFO : EPOCH 3 - PROGRESS: at 95.00% examples, 213423 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:16:49,471 : INFO : EPOCH 3 - PROGRESS: at 96.36% examples, 213490 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:16:50,502 : INFO : EPOCH 3 - PROGRESS: at 97.73% examples, 213507 words/s, in_qsize 8, out_qsize 0\n",
      "2022-03-22 05:16:51,542 : INFO : EPOCH 3 - PROGRESS: at 99.15% examples, 213581 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:16:52,148 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-03-22 05:16:52,150 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-22 05:16:52,177 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-22 05:16:52,191 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-22 05:16:52,192 : INFO : EPOCH - 3 : training on 23583894 raw words (16325329 effective words) took 76.4s, 213624 effective words/s\n",
      "2022-03-22 05:16:53,252 : INFO : EPOCH 4 - PROGRESS: at 1.22% examples, 190521 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:16:54,261 : INFO : EPOCH 4 - PROGRESS: at 2.58% examples, 204673 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:16:55,286 : INFO : EPOCH 4 - PROGRESS: at 3.87% examples, 205915 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:16:56,308 : INFO : EPOCH 4 - PROGRESS: at 5.23% examples, 208441 words/s, in_qsize 8, out_qsize 0\n",
      "2022-03-22 05:16:57,388 : INFO : EPOCH 4 - PROGRESS: at 6.60% examples, 207712 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:16:58,407 : INFO : EPOCH 4 - PROGRESS: at 7.96% examples, 209197 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:16:59,449 : INFO : EPOCH 4 - PROGRESS: at 9.33% examples, 209656 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:17:00,470 : INFO : EPOCH 4 - PROGRESS: at 10.71% examples, 210546 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:17:01,502 : INFO : EPOCH 4 - PROGRESS: at 12.04% examples, 210999 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:17:02,535 : INFO : EPOCH 4 - PROGRESS: at 13.42% examples, 211270 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:17:03,542 : INFO : EPOCH 4 - PROGRESS: at 14.74% examples, 211362 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:17:04,580 : INFO : EPOCH 4 - PROGRESS: at 16.09% examples, 211568 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:17:05,608 : INFO : EPOCH 4 - PROGRESS: at 17.45% examples, 211857 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:17:06,641 : INFO : EPOCH 4 - PROGRESS: at 18.79% examples, 212039 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:17:07,666 : INFO : EPOCH 4 - PROGRESS: at 20.15% examples, 212254 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:17:08,669 : INFO : EPOCH 4 - PROGRESS: at 21.50% examples, 212727 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:17:09,673 : INFO : EPOCH 4 - PROGRESS: at 22.71% examples, 211967 words/s, in_qsize 8, out_qsize 0\n",
      "2022-03-22 05:17:10,684 : INFO : EPOCH 4 - PROGRESS: at 24.12% examples, 212341 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:17:11,709 : INFO : EPOCH 4 - PROGRESS: at 25.48% examples, 212485 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:17:12,728 : INFO : EPOCH 4 - PROGRESS: at 26.83% examples, 212703 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:17:13,730 : INFO : EPOCH 4 - PROGRESS: at 28.13% examples, 212760 words/s, in_qsize 8, out_qsize 0\n",
      "2022-03-22 05:17:14,766 : INFO : EPOCH 4 - PROGRESS: at 29.38% examples, 212175 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:17:15,804 : INFO : EPOCH 4 - PROGRESS: at 30.73% examples, 212229 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:17:16,821 : INFO : EPOCH 4 - PROGRESS: at 32.06% examples, 212450 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:17:17,841 : INFO : EPOCH 4 - PROGRESS: at 33.33% examples, 212103 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:17:18,887 : INFO : EPOCH 4 - PROGRESS: at 34.68% examples, 212077 words/s, in_qsize 6, out_qsize 1\n",
      "2022-03-22 05:17:19,930 : INFO : EPOCH 4 - PROGRESS: at 36.02% examples, 212075 words/s, in_qsize 6, out_qsize 1\n",
      "2022-03-22 05:17:20,968 : INFO : EPOCH 4 - PROGRESS: at 37.35% examples, 212118 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:17:21,992 : INFO : EPOCH 4 - PROGRESS: at 38.72% examples, 212262 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:17:23,052 : INFO : EPOCH 4 - PROGRESS: at 40.07% examples, 212145 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:17:24,093 : INFO : EPOCH 4 - PROGRESS: at 41.41% examples, 212153 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:17:25,139 : INFO : EPOCH 4 - PROGRESS: at 42.75% examples, 212124 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:17:26,178 : INFO : EPOCH 4 - PROGRESS: at 44.06% examples, 212141 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:17:27,207 : INFO : EPOCH 4 - PROGRESS: at 45.41% examples, 212231 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:17:28,234 : INFO : EPOCH 4 - PROGRESS: at 46.75% examples, 212317 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:17:29,240 : INFO : EPOCH 4 - PROGRESS: at 48.11% examples, 212521 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:17:30,256 : INFO : EPOCH 4 - PROGRESS: at 49.42% examples, 212486 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:17:31,257 : INFO : EPOCH 4 - PROGRESS: at 50.71% examples, 212524 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:17:32,291 : INFO : EPOCH 4 - PROGRESS: at 52.06% examples, 212563 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:17:33,301 : INFO : EPOCH 4 - PROGRESS: at 53.29% examples, 212220 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:17:34,315 : INFO : EPOCH 4 - PROGRESS: at 54.63% examples, 212365 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:17:35,344 : INFO : EPOCH 4 - PROGRESS: at 55.99% examples, 212426 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:17:36,393 : INFO : EPOCH 4 - PROGRESS: at 57.35% examples, 212385 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:17:37,424 : INFO : EPOCH 4 - PROGRESS: at 58.70% examples, 212439 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:17:38,456 : INFO : EPOCH 4 - PROGRESS: at 60.05% examples, 212479 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:17:39,494 : INFO : EPOCH 4 - PROGRESS: at 61.40% examples, 212485 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:17:40,515 : INFO : EPOCH 4 - PROGRESS: at 62.72% examples, 212435 words/s, in_qsize 8, out_qsize 0\n",
      "2022-03-22 05:17:41,524 : INFO : EPOCH 4 - PROGRESS: at 64.01% examples, 212433 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:17:42,571 : INFO : EPOCH 4 - PROGRESS: at 65.37% examples, 212418 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:17:43,610 : INFO : EPOCH 4 - PROGRESS: at 66.70% examples, 212424 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:17:44,645 : INFO : EPOCH 4 - PROGRESS: at 68.05% examples, 212455 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:17:45,709 : INFO : EPOCH 4 - PROGRESS: at 69.40% examples, 212366 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:17:46,732 : INFO : EPOCH 4 - PROGRESS: at 70.77% examples, 212435 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:17:47,762 : INFO : EPOCH 4 - PROGRESS: at 72.14% examples, 212472 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:17:48,805 : INFO : EPOCH 4 - PROGRESS: at 73.46% examples, 212457 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:17:49,857 : INFO : EPOCH 4 - PROGRESS: at 74.79% examples, 212422 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:17:50,865 : INFO : EPOCH 4 - PROGRESS: at 76.14% examples, 212537 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:17:51,871 : INFO : EPOCH 4 - PROGRESS: at 77.46% examples, 212534 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:17:52,898 : INFO : EPOCH 4 - PROGRESS: at 78.79% examples, 212462 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:17:53,911 : INFO : EPOCH 4 - PROGRESS: at 80.11% examples, 212447 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:17:54,927 : INFO : EPOCH 4 - PROGRESS: at 81.42% examples, 212421 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:17:55,963 : INFO : EPOCH 4 - PROGRESS: at 82.79% examples, 212434 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:17:56,999 : INFO : EPOCH 4 - PROGRESS: at 84.17% examples, 212456 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:17:58,017 : INFO : EPOCH 4 - PROGRESS: at 85.57% examples, 212528 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:17:59,037 : INFO : EPOCH 4 - PROGRESS: at 86.91% examples, 212593 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:18:00,048 : INFO : EPOCH 4 - PROGRESS: at 88.28% examples, 212684 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:18:01,073 : INFO : EPOCH 4 - PROGRESS: at 89.64% examples, 212730 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:18:02,092 : INFO : EPOCH 4 - PROGRESS: at 91.00% examples, 212785 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:18:03,106 : INFO : EPOCH 4 - PROGRESS: at 92.32% examples, 212762 words/s, in_qsize 8, out_qsize 0\n",
      "2022-03-22 05:18:04,118 : INFO : EPOCH 4 - PROGRESS: at 93.66% examples, 212739 words/s, in_qsize 8, out_qsize 0\n",
      "2022-03-22 05:18:05,141 : INFO : EPOCH 4 - PROGRESS: at 95.05% examples, 212781 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:18:06,146 : INFO : EPOCH 4 - PROGRESS: at 96.36% examples, 212784 words/s, in_qsize 8, out_qsize 0\n",
      "2022-03-22 05:18:07,203 : INFO : EPOCH 4 - PROGRESS: at 97.73% examples, 212737 words/s, in_qsize 8, out_qsize 0\n",
      "2022-03-22 05:18:08,212 : INFO : EPOCH 4 - PROGRESS: at 99.10% examples, 212820 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:18:08,808 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-03-22 05:18:08,858 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-22 05:18:08,860 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-22 05:18:08,861 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-22 05:18:08,861 : INFO : EPOCH - 4 : training on 23583894 raw words (16325697 effective words) took 76.7s, 212959 effective words/s\n",
      "2022-03-22 05:18:09,917 : INFO : EPOCH 5 - PROGRESS: at 1.22% examples, 190493 words/s, in_qsize 8, out_qsize 0\n",
      "2022-03-22 05:18:10,930 : INFO : EPOCH 5 - PROGRESS: at 2.58% examples, 204355 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:18:11,980 : INFO : EPOCH 5 - PROGRESS: at 3.91% examples, 206323 words/s, in_qsize 7, out_qsize 0\n",
      "2022-03-22 05:18:13,015 : INFO : EPOCH 5 - PROGRESS: at 5.27% examples, 208040 words/s, in_qsize 7, out_qsize 0\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',level=logging.INFO)\n",
    "\n",
    "model = word2vec.Word2Vec(sentences, workers=W2V_NUM_WORKERS, \\\n",
    "        vector_size=W2V_NUM_FEATURES, min_count = W2V_MIN_WORD_COUNT, \\\n",
    "        window = W2V_CONTEXT, sg = 1, sample = W2V_DOWNSAMPLING)\n",
    "\n",
    "model.init_sims(replace=True)\n",
    "model.save('model202203202347')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-22 04:58:51,346 : INFO : loading Word2Vec object from ./model202203202347\n",
      "2022-03-22 04:58:51,377 : INFO : loading wv recursively from ./model202203202347.wv.* with mmap=None\n",
      "2022-03-22 04:58:51,378 : INFO : setting ignored attribute cum_table to None\n",
      "2022-03-22 04:58:51,485 : INFO : Word2Vec lifecycle event {'fname': './model202203202347', 'datetime': '2022-03-22T04:58:51.485341', 'gensim': '4.1.2', 'python': '3.7.11 (default, Jul 27 2021, 14:32:16) \\n[GCC 7.5.0]', 'platform': 'Linux-5.4.0-100-generic-x86_64-with-debian-buster-sid', 'event': 'loaded'}\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec.load('./model202203202347')\n",
    "# model.train(more_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad\n",
      "\n",
      "[('wonderful', 0.6245879530906677), ('terrific', 0.6124959588050842), ('fantastic', 0.572205662727356), ('fine', 0.5539406538009644), ('excellent', 0.5435725450515747), ('good', 0.5107054114341736), ('brilliant', 0.5039620995521545), ('fabulous', 0.498401939868927), ('superb', 0.4918639361858368), ('outstanding', 0.4840160310268402)]\n",
      "\n",
      "model.wv.vectors.shape = (12625, 400)\n",
      "\n",
      "12625\n"
     ]
    }
   ],
   "source": [
    "print(f'{model.wv.doesnt_match(\"good great awesome bad\".split())}\\n') \n",
    "\n",
    "print(f'{model.wv.most_similar(\"great\")}\\n')\n",
    "print(f'model.wv.vectors.shape = {model.wv.vectors.shape}\\n')\n",
    "print(f'{len(model.wv.index_to_key)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordlist_to_vector(words, model):\n",
    "\n",
    "    wordVecList = []\n",
    "    wordSet = set(model.wv.index_to_key)\n",
    "\n",
    "    for word in words:\n",
    "        if word in wordSet:\n",
    "            wordVecList.append(model.wv[word])\n",
    "\n",
    "    if len(wordVecList) > 0:\n",
    "        return np.mean(wordVecList, axis=0)\n",
    "    else:\n",
    "        raise Exception('len(wordVecList) = 0')\n",
    "        return np.zeros((W2V_NUM_FEATURES,), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reviews_to_vectors(reviews, model):\n",
    "    cleanWordLists = []\n",
    "    for review in reviews:\n",
    "        cleanWordLists.append(review_to_wordlist(review, remove_stopwords=True, lemmalization=True))\n",
    "    \n",
    "    vectors = []\n",
    "    vectorCount = 0\n",
    "    for cleanWordList in cleanWordLists:\n",
    "        vectors.append(wordlist_to_vector(cleanWordList, model))\n",
    "\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['sentiment', 'review'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "vec = wordlist_to_vector(sentences[0], model)\n",
    "\n",
    "train_df = labeled_df.drop(labels=['id'], axis=1)\n",
    "print(train_df.columns)\n",
    "labeled_x = train_df.drop(labels=['sentiment'], axis=1)\n",
    "labeled_y = train_df['sentiment']\n",
    "labeled_y.to_numpy()\n",
    "\n",
    "vectors = reviews_to_vectors(labeled_x['review'], model)\n",
    "vectors = np.stack(vectors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest K-fold: 0.83872\n",
      "XGBoost K-fold: 0.8639199999999999\n"
     ]
    }
   ],
   "source": [
    "train_x, valid_x, train_y, valid_y = train_test_split(vectors, labeled_y.to_numpy(), test_size=0.3, random_state=12345)\n",
    "\n",
    "all_x = vectors\n",
    "all_y = labeled_y.to_numpy()\n",
    "print()\n",
    "\n",
    "randomForest = RandomForestClassifier(n_estimators=100)\n",
    "xgboostModel = XGBClassifier(n_estimators=100, learning_rate=0.3, use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "print(f'Random Forest K-fold: {cross_val_score(randomForest, all_x, all_y, cv=10, scoring=\"accuracy\").mean()}')\n",
    "print(f'XGBoost K-fold: {cross_val_score(xgboostModel, all_x, all_y, cv=10, scoring=\"accuracy\").mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomForest.fit(all_x, all_y)\n",
    "xgboostModel.fit(all_x, all_y)\n",
    "\n",
    "classifierModel = xgboostModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1649658/3022885222.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./testData.tsv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreviews_to_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'review'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msample_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./sampleSubmission.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1649658/2112003116.py\u001b[0m in \u001b[0;36mreviews_to_vectors\u001b[0;34m(reviews, model)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mvectorCount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcleanWordList\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcleanWordLists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mvectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwordlist_to_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleanWordList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1649658/2405795603.py\u001b[0m in \u001b[0;36mwordlist_to_vector\u001b[0;34m(words, model)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwordSet\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mwordVecList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwordVecList\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key_or_keys)\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_to_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_or_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m         \"\"\"Get vector representation of `key_or_keys`.\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv('./testData.tsv', sep='\\t', header=0)\n",
    "test_x = reviews_to_vectors(test_df['review'], model)\n",
    "test_x = np.stack(test_x, axis=0)\n",
    "\n",
    "sample_df = pd.read_csv('./sampleSubmission.csv')\n",
    "sample_df['sentiment'] = np.squeeze(randomForest.predict(test_x))\n",
    "sample_df.to_csv('./sampleSubmission.csv', index=False, quoting=csv.QUOTE_NONNUMERIC)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('base')",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
